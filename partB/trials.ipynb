{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import wandb\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "MAX_EPOCHS = 10\n",
    "LEARNING_RATE = 3e-4\n",
    "FEATURE_LEARNING_RATE = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTunedEfficientNet(pl.LightningModule):\n",
    "    def __init__(self, num_classes=10, learning_rate=3e-4, feature_learning_rate=1e-5):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.feature_learning_rate = feature_learning_rate\n",
    "        \n",
    "        # Load pre-trained model\n",
    "        self.model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Freeze early layers (first 4 blocks)\n",
    "        for i, block in enumerate(self.model.features):\n",
    "            if i < 4:  # Freeze first 4 blocks\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier with new one for our classes\n",
    "        num_features = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        # Save hyperparameters for checkpointing\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        # Log metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        # Log metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        # Log metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Use different learning rates for pre-trained feature layers and new classifier\n",
    "        classifier_params = self.model.classifier.parameters()\n",
    "        feature_params = self.model.features.parameters()\n",
    "        \n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': classifier_params, 'lr': self.learning_rate},\n",
    "            {'params': feature_params, 'lr': self.feature_learning_rate}\n",
    "        ])\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "                'interval': 'epoch'\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: bullseye2608 (bullseye2608-indian-institute-of-technology-madras) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\DELL\\Desktop\\Coding\\Python\\DL\\Assignment 2\\da6401_assignment2\\partB\\wandb\\run-20250418_230452-sirgtxvq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison/runs/sirgtxvq' target=\"_blank\">vital-dust-4</a></strong> to <a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison' target=\"_blank\">https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison/runs/sirgtxvq' target=\"_blank\">https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison/runs/sirgtxvq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fine-tuned EfficientNetV2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Initialize WandB\n",
    "wandb.init(project=\"inaturalist-comparison\")\n",
    "\n",
    "data_directory = r'C:\\Users\\DELL\\Desktop\\Coding\\Python\\DL\\Assignment 2\\da6401_assignment2\\data\\inaturalist_12K'\n",
    "data_module = iNaturalistDataModule(\n",
    "        data_dir=data_directory,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        use_data_augmentation=True\n",
    "    )\n",
    "data_module.setup()\n",
    "\n",
    "# Setup callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='inaturalist-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"inaturalist-cnn\")\n",
    "\n",
    "# Train fine-tuned model\n",
    "print(\"Training fine-tuned EfficientNetV2...\")\n",
    "fine_tuned_model = FineTunedEfficientNet(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    feature_learning_rate=FEATURE_LEARNING_RATE\n",
    ")\n",
    "\n",
    "trainer_fine_tuned = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    logger=wandb_logger,\n",
    "    log_every_n_steps=10,\n",
    "    deterministic=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "c:\\Users\\DELL\\.conda\\envs\\DL\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "c:\\Users\\DELL\\.conda\\envs\\DL\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\DELL\\Desktop\\Coding\\Python\\DL\\Assignment 2\\da6401_assignment2\\partB\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\DELL\\.conda\\envs\\DL\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type         | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | model | EfficientNet | 20.2 M | train\n",
      "-----------------------------------------------\n",
      "19.3 M    Trainable params\n",
      "903 K     Non-trainable params\n",
      "20.2 M    Total params\n",
      "80.761    Total estimated model params size (MB)\n",
      "714       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d466d951a8384be3bb07d3d6bd25f132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8338b768670d4e57ba0c18cc5959e328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd91b11b6254d5aabc419a59fba80f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ab8ef334204b7095c32e1ce91fc39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2b4477c2234d239ff563a1302dd9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5cb0f5a02f48af90ce219e6bba9920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5331c089ef8455a8ff6d9467779c9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fea8f14c5642bab03c2d9aa6a4115e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e993248add4b298432d7cd6da10edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad914626bde4f40af1073ae1181bcfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889deaad0f664361a0dd7197714c6dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16d341239d1460787f246fd84bed9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer_fine_tuned.fit(fine_tuned_model, data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f243815f2d64697b6f04d1b44d11fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8669999837875366     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.49156495928764343    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8669999837875366    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.49156495928764343   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇█████</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▅▆▆▆▇▇███</td></tr><tr><td>train_acc_step</td><td>▁▄▅▄▆▇▆▆▆▅▅▆▇▇▆▆▇▆▇▆█▆▇▇▆█▆▇▇▇▆▇▇▇█▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▃▄▂▃▂▂▂▂▂▄▂▂▁▂▂▂▃▂▂▂▁▂▂▂▂▁▂▂▂▂▁▂▂▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>val_loss</td><td>▂▂▁▁▁▁▁▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_acc</td><td>0.867</td></tr><tr><td>test_loss</td><td>0.49156</td></tr><tr><td>train_acc_epoch</td><td>0.93287</td></tr><tr><td>train_acc_step</td><td>1</td></tr><tr><td>train_loss_epoch</td><td>0.20449</td></tr><tr><td>train_loss_step</td><td>0.08749</td></tr><tr><td>trainer/global_step</td><td>2500</td></tr><tr><td>val_acc</td><td>0.876</td></tr><tr><td>val_loss</td><td>1.46932</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-leaf-2</strong> at: <a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison/runs/lyam2kd5' target=\"_blank\">https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison/runs/lyam2kd5</a><br> View project at: <a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison' target=\"_blank\">https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250418_173343-lyam2kd5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Test fine-tuned model\n",
    "fine_tuned_results = trainer_fine_tuned.test(fine_tuned_model, data_module)\n",
    "\n",
    "# Now train the model from scratch\n",
    "wandb.finish()  # End the previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "def create_prediction_grid(model, test_dataset, class_names):\n",
    "    # Select 30 random images (for a 10×3 grid)\n",
    "    num_samples = min(30, len(test_dataset))\n",
    "    indices = np.random.choice(len(test_dataset), num_samples, replace=False)\n",
    "    \n",
    "    # Create a figure with 10 rows and 3 columns\n",
    "    fig, axes = plt.subplots(10, 3, figsize=(12, 30))\n",
    "    \n",
    "    # Define denormalization transform\n",
    "    denorm = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0, 0, 0], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "        transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
    "    ])\n",
    "    \n",
    "    # Plot each image with prediction\n",
    "    model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(indices):\n",
    "            row = i // 3\n",
    "            col = i % 3\n",
    "            \n",
    "            # Get the image and label\n",
    "            img, true_label = test_dataset[idx]\n",
    "            img_tensor = img.unsqueeze(0).to(model.device)\n",
    "            \n",
    "            # Make prediction\n",
    "            output = model(img_tensor)\n",
    "            _, pred_label = torch.max(output, 1)\n",
    "            \n",
    "            # Get probabilities\n",
    "            probs = torch.nn.functional.softmax(output, dim=1)[0]\n",
    "            \n",
    "            # Convert image for display\n",
    "            img_display = denorm(img).permute(1, 2, 0).cpu().numpy()\n",
    "            img_display = np.clip(img_display, 0, 1)\n",
    "            \n",
    "            # Get prediction info\n",
    "            true_class = class_names[true_label]\n",
    "            pred_class = class_names[pred_label.item()]\n",
    "            is_correct = true_label == pred_label.item()\n",
    "            \n",
    "            # Plot image\n",
    "            ax = axes[row, col]\n",
    "            ax.imshow(img_display)\n",
    "            \n",
    "            # Set the title color based on correct/wrong prediction\n",
    "            title_color = 'green' if is_correct else 'red'\n",
    "            \n",
    "            # Add title with prediction and confidence\n",
    "            conf = probs[pred_label.item()].item() * 100\n",
    "            ax.set_title(f\"True: {true_class}\\nPred: {pred_class}\\nConf: {conf:.1f}%\", \n",
    "                        color=title_color, fontsize=10)\n",
    "            \n",
    "            # Remove ticks\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "    # Add overall title\n",
    "    # plt.suptitle(\"Model Predictions on Test Data\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig('prediction_grid.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Log the figure to wandb\n",
    "    wandb.log({\"Model Predictions on Test Data\": wandb.Image(fig)})\n",
    "    \n",
    "    # Close the figure\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-oath-3</strong> at: <a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison/runs/vmofkzcb' target=\"_blank\">https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison/runs/vmofkzcb</a><br> View project at: <a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison' target=\"_blank\">https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-comparison</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250418_174834-vmofkzcb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"inaturalist-cnn\")\n",
    "create_prediction_grid(fine_tuned_model, data_module.test_dataset, data_module.test_dataloader().dataset.classes)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: bullseye2608 (bullseye2608-indian-institute-of-technology-madras) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\DELL\\Desktop\\Coding\\Python\\DL\\Assignment 2\\da6401_assignment2\\partB\\wandb\\run-20250419_003311-b3myx2e7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-cnn/runs/b3myx2e7' target=\"_blank\">ImageLogger_2025-04-19_00-33-09</a></strong> to <a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-cnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-cnn' target=\"_blank\">https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-cnn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-cnn/runs/b3myx2e7' target=\"_blank\">https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-cnn/runs/b3myx2e7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ImageLogger_2025-04-19_00-33-09</strong> at: <a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-cnn/runs/b3myx2e7' target=\"_blank\">https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-cnn/runs/b3myx2e7</a><br> View project at: <a href='https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-cnn' target=\"_blank\">https://wandb.ai/bullseye2608-indian-institute-of-technology-madras/inaturalist-cnn</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250419_003311-b3myx2e7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "run_name = f\"ImageLogger_{timestamp}\"\n",
    "# Initialize W&B run\n",
    "run = wandb.init(project=\"inaturalist-cnn\", name=run_name)\n",
    "\n",
    "# Log the PNG image\n",
    "image = wandb.Image(\"./prediction_grid.png\", caption=\"Model Predictions on Test Data\")\n",
    "run.log({\"Model Predictions on Test Data\": image})\n",
    "\n",
    "# Finish the run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
